from __future__ import annotations

from typing import Any, Dict, List, Tuple

import json
import os
import re

import httpx
from fastapi import HTTPException, status

from app.config import settings
from app.utils.logger import logger


_AI_SQL_JSON_RE = re.compile(r"\{[\s\S]*\}")


class AiSqlGenerationError(RuntimeError):
    """Raised when the AI provider fails to return valid SQL JSON."""


def _extract_table_identifiers(sql: str) -> List[str]:
    """Best-effort extraction of table identifiers from FROM / JOIN clauses.

    This is deliberately conservative and is *not* a full SQL parser, but it is
    enough to enforce a simple whitelist of tables for read-only analytics
    queries generated by the AI engine.
    """

    candidates: List[str] = []
    # Match FROM <ident> and JOIN <ident>; capture the identifier that follows.
    for pattern in (r"\bFROM\s+([a-zA-Z0-9_\.\"]+)", r"\bJOIN\s+([a-zA-Z0-9_\.\"]+)"):
        for match in re.finditer(pattern, sql, flags=re.IGNORECASE):
            ident = match.group(1)
            # Strip optional schema prefixes and quotes: public.tbl_foo -> tbl_foo
            ident = ident.strip() or ""
            ident = ident.strip('"')
            if "." in ident:
                ident = ident.split(".")[-1]
            if ident:
                candidates.append(ident)
    return candidates


def _validate_sql(sql: str, allowed_tables: List[str]) -> None:
    """Validate that generated SQL is read-only and uses only whitelisted tables.

    The rules are intentionally strict:
    - Only a single statement (no semicolons).
    - No data-modifying / DDL keywords.
    - All referenced tables in FROM/JOIN must be in ``allowed_tables``.
    """

    sql_stripped = sql.strip()
    if not sql_stripped:
        raise AiSqlGenerationError("AI returned an empty SQL string")

    if ";" in sql_stripped:
        raise AiSqlGenerationError("Multiple SQL statements are not allowed; remove semicolons")

    upper = sql_stripped.upper()
    forbidden = [
        "UPDATE ",
        "DELETE ",
        "INSERT ",
        "UPSERT ",
        "MERGE ",
        "ALTER ",
        "DROP ",
        "TRUNCATE ",
        "CREATE ",
        "GRANT ",
        "REVOKE ",
        "EXEC ",
        "CALL ",
    ]
    for kw in forbidden:
        if kw in upper:
            raise AiSqlGenerationError(f"Forbidden SQL keyword detected: {kw.strip()}")

    # Basic sanity: must be a SELECT query.
    if not upper.startswith("SELECT "):
        raise AiSqlGenerationError("Only SELECT queries are allowed")

    # Enforce table whitelist for FROM/JOIN clauses.
    allowed_set = {name.lower() for name in allowed_tables}
    referenced = _extract_table_identifiers(sql_stripped)
    unknown: List[str] = []
    for ident in referenced:
        if ident.lower() not in allowed_set:
            unknown.append(ident)

    if unknown:
        raise AiSqlGenerationError(
            "SQL references non-whitelisted tables: " + ", ".join(sorted(set(unknown)))
        )


async def build_sql_from_prompt(prompt: str, *, allowed_tables: List[str]) -> Tuple[str, List[str]]:
    """Call OpenAI Chat Completions API to turn natural language into SQL.

    Returns a tuple ``(sql, columns)`` where ``columns`` is the ordered list of
    column names that the AI *expects* the query to return. The caller still
    validates the SQL against a whitelist and may derive the final columns from
    the actual query result set.
    """

    api_key = settings.OPENAI_API_KEY or os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="OPENAI_API_KEY is not configured on the backend; contact an administrator.",
        )

    model = settings.OPENAI_MODEL
    base_url = settings.OPENAI_API_BASE_URL.rstrip("/")

    system_prompt = (
        "You are an internal analytics SQL generator for a private eBay operations app. "
        "Given a natural language Russian or English request, you must output STRICT JSON only, "
        "with fields: {\n  \"sql\": string,\n  \"columns\": [list of column names]\n}. "
        "Rules: (1) Only generate a single SELECT statement. (2) Use ONLY the following "
        "PostgreSQL tables: "
        + ", ".join(sorted(allowed_tables))
        + ". (3) Do not use CTEs, window functions, or subqueries in the first iteration; keep queries simple. "
        "(4) Prefer LIMIT 200. (5) NEVER include UPDATE/INSERT/DELETE/DDL or comments. "
        "(6) When searching for complaints about bad packaging or damaged items, focus on body/subject fields."
    )

    payload: Dict[str, Any] = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": (
                    "Natural-language analytics request:\n" + prompt.strip() + "\n" +
                    "Return ONLY JSON with 'sql' and 'columns'. Do not wrap in markdown."
                ),
            },
        ],
        "temperature": 0.1,
        "max_tokens": 512,
    }

    url = f"{base_url}/v1/chat/completions"
    try:
        async with httpx.AsyncClient(timeout=20.0) as client:
            resp = await client.post(
                url,
                headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
                json=payload,
            )
    except Exception as exc:  # pragma: no cover - network failures
        logger.error("AI SQL provider request failed: %s", exc)
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="Failed to contact AI provider for SQL generation.",
        ) from exc

    if resp.status_code >= 400:
        logger.error("AI SQL provider HTTP %s: %s", resp.status_code, resp.text[:500])
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail=f"AI provider returned HTTP {resp.status_code} while generating SQL.",
        )

    try:
        data = resp.json()
        content = data["choices"][0]["message"]["content"]
    except Exception as exc:  # pragma: no cover - defensive
        logger.error("Unexpected AI provider response structure: %s", resp.text[:500])
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="AI provider returned an unexpected response payload.",
        ) from exc

    if not content:
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="AI provider returned empty content while generating SQL.",
        )

    # Some models may wrap JSON in text; extract the first JSON object.
    match = _AI_SQL_JSON_RE.search(content)
    if not match:
        logger.error("AI provider did not return JSON: %s", content[:500])
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="AI provider did not return valid JSON for SQL generation.",
        )

    try:
        payload_json = json.loads(match.group(0))
    except json.JSONDecodeError as exc:
        logger.error("Failed to parse AI SQL JSON: %s", content[:500])
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="AI provider returned malformed JSON for SQL generation.",
        ) from exc

    sql = str(payload_json.get("sql") or "").strip()
    columns = payload_json.get("columns") or []
    if not isinstance(columns, list):
        columns = []

    # Validate generated SQL against our whitelist and safety rules.
    _validate_sql(sql, allowed_tables)

    # Normalise column names to strings.
    col_names: List[str] = []
    for col in columns:
        try:
            name = str(col).strip()
        except Exception:  # pragma: no cover - defensive
            continue
        if name:
            col_names.append(name)

    return sql, col_names
